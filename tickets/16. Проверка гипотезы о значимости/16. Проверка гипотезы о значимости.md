# 16. Проверка гипотезы о значимости выборочного коэффициента корреляции. Интервальная оценка линейного коэффициента корреляции.

**Выборочный коэффициент корреляции** определяется выражением: 

$$r_{xy}=\frac{cov(X,Y)}{\sigma_{x}\sigma_{y}} \qquad$$

где $\sigma_{x}$, $\sigma_{y}$ — средние квадратические выборочные отклонения, соответственно, для переменной $X$ и $Y$.

Коэффициент корреляции является безразмерной величиной, изменяющейся в пределах $-1\le r_{xy}\le 1$.

Коэффициент корреляции показывает тесноту линейной связи двух случайных величин:
* $r>0$ при положительной связи и $r=1$ при строго положительной линейной связи; случайные величины $X$ и $Y$ с точностью до случайных погрешностей одновременно убывают или возрастают, т. е. наблюдается «положительная корреляция».
* $r<0$ при отрицательной связи и $r=-1$ при строгой отрицательной линейной связи; случайные величины $X$ и $Y$ с точностью до случайных погрешностей одновременно убывают или возрастают, т. е. наблюдается «положительная корреляция».
* $r=0$ при отсутствии линейной связи.

Случайные величины $X, Y$ называются **некоррелированными**, если $r=0$, и **коррелированными**, если $r\ne 0$.

Независимость случайных величин $X, Y$ означает отсутствие любой связи (линейной и нелинейной), а некоррелированность — отсутствие только линейной связи.

Свойства:
* Если случайные величины $X, Y$ независимы, то они некоррелированы ($r = 0$), но из некоррелированности не следует их независимость, т.е. равенство $r = 0$ указывает на отсутствие только ЛИНЕЙНОЙ связи между переменными, но не на отсутствие связи между ними вообще.
* Упрощенная формула для определения коэффициента корреляции:

$$r_{xy}=\frac{\overline{xy}-\overline{x}\overline{y}}{\sigma_{x}\sigma_{y}}, \qquad \text{где } \overline{xy}=\frac{1}{n}\sum_{i=1}^{n}x_{i}y_{i}$$

Если для генеральной совокупности генеральный коэффициент корреляции $\rho=0$, то это не всегда означает, что и для выборочной совокупности $r=0$.

Следует помнить, что коэффициент корреляции $r_{xy}$ характеризует только тесноту связи для зависимостей линейного вида. Для нелинейных видов связи (например, для параболического типа) результаты получаются просто абсурдными.

Если случайные величины $X$ и $Y$ связаны ТОЧНОЙ линейной функциональной зависимостью $(Y = a + b\cdot X)$, то $r_{xy}=\pm 1$. В общем случае линейный коэффициент корреляции может принимать значение в пределах $-1\le r_{xy}\le 1$.

На практике коэффициент корреляции определяется чаще всего по выборочным данным, следовательно, полученные выборочные показатели отличаются от аналогичных показателей в генеральной совокупности. 62В связи с этим необходимо определять точность показателей корреляции и границы доверительных интервалов.

**Оценка значимости коэффициента корреляции**

Значимость линейного коэффициента корреляции проверяется гипотезой $H_{0}$ о равенстве коэффициента корреляции нулю:

$$H_{0}:r_{xy}=0$$
  
$$H_{1}:r_{xy}\ne 0$$

При проверке этой гипотезы используется $t$-статистика, имеющая распределение Стьюдента с $k=n-2$ степенями свободы:

$$t_{B}=\sqrt{\frac{r^{2}}{1-r^{2}}(n-2)}=\frac{|r|}{\sqrt{(1-r^{2})}}\sqrt{(n-2)}$$

Далее вычисляется $t_{kp}=t(\alpha,k)$ — табличное значение $t$-критерия Стьюдента с входными параметрами $\alpha$ и $k$ ($\alpha$ — уровень значимости, $k=n-2$ — число степеней свободы). 

Если определенное по выборке значение $t_{B}>t_{kp}$, то гипотеза $H_{0}:r_{xy}=0$ отвергается, что свидетельствует о значимости линейного коэффициента корреляции (отличии от нуля), а следовательно, и о статистической существенности зависимости между $X$ и $Y$.


**Интервальная оценка коэффициента корреляции**

Рассмотренные критерии значимости коэффициентов корреляции рекомендуется применять при большом числе наблюдений $n$, а также если значение $r$ не близко к $\pm 1$. При нарушении указанных условий распределение статистики отличается от распределения Стьюдента. Как оценить $\rho$ на небольших выборках или когда выборочный коэффициент корреляции $r\rightarrow\pm 1$?

Для устранения этого затруднения Р.Фишер предложил ввести вспомогательную величину $Z$, связанную с коэффициентом корреляции соотношением:

$$Z=\frac{1}{2}ln\frac{1+r}{1-r} \qquad$$

Статистика $Z$ при $n>10$ и $r\rightarrow\pm 1$ распределена приблизительно нормально с генеральным средним и дисперсией, равными:

$$M(Z)\approx\frac{1}{2}ln\frac{1+\rho}{1-\rho}+\frac{\rho}{2(n-1)}$$$$D(Z)\approx\frac{1}{n-3}$$

Можно показать, что когда $r\in(-1;1)$, то $Z\in(-\infty;+\infty)$.

Для определения интервальной оценки генерального коэффициента корреляции действуют по следующему **алгоритму**:
* На основе $z$-преобразования Фишера вычисляют значение:

$$z_{B}=\frac{1}{2}ln\frac{1+r}{1-r}$$

или находят по специальным таблицам.
* Из условия $\Phi(z_{N})=1-\alpha$ по таблице функции Лапласа находится значение $z_{N}=\Phi^{-1}(1-\alpha)$.
* Строят доверительный интервал для $Z$:

$$z_{p}-z_{N}\cdot\sigma_{z}\le z\le z_{p}+z_{N}\cdot\sigma_{z}$$

где $\sigma_{z}=1/\sqrt{(n-3)}$ — среднее квадратическое отклонение случайной величины $Z$.

Тогда окончательная формула для интервальной оценки $z$ имеет вид:

$$z_p - z_N \cdot \frac{1}{\sqrt{(n - 3)}} \le z \le z_p + z_N \cdot \frac{1}{\sqrt{(n - 3)}}$$

* Для определения границ доверительного интервала для генерального коэффициента корреляции $\rho$ (для перехода от $z$ к $\rho$) существуют специальные таблицы. При ее отсутствии переход может быть осуществлен по формуле: $\rho = \text{th } z$ ($\text{th}$ — тангенс гиперболический). То есть:

$$\text{th} \left( z_p - z_N \cdot \frac{1}{\sqrt{(n - 3)}} \right) \le \rho \le \text{th} \left( z_p + z_N \cdot \frac{1}{\sqrt{(n - 3)}} \right)$$

Стандартная ошибка линейного коэффициента корреляции рассчитывается по формуле:

$$\sigma_r = \sqrt{\frac{1 - r^2}{n - 2}}$$

